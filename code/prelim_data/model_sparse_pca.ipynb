{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_load import *\n",
    "from model_fit_functions import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import SparsePCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: Complete_Spectral_Data\\Training_Data Physical properties shape: (1346, 5) Spectral prop shape: (1346, 110001)\n",
      "Directory: Complete_Spectral_Data\\Test_Data Physical properties shape: (810, 5) Spectral prop shape: (810, 110001)\n",
      "Spectral data shape (2156, 110001)\n",
      "Physical data shape (2156, 5)\n"
     ]
    }
   ],
   "source": [
    "data_dict =  load_split_pool(1346, 430, 10, scale = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sparse_pca(alpha, n_components, train_df_pooled, val_df_pooled, sparse_pca_results):\n",
    "    '''\n",
    "    Estimate spars ePCA model, project the original features to the subspace and then recover the \n",
    "    original dat (as much as possible) and calculate RMSE loss.\n",
    "    \n",
    "    Inputs:\n",
    "    - alpha: regularisation parameter\n",
    "    - train_df_pooled: train set\n",
    "    - val_df_pooled: validation set\n",
    "    - sparse_pca_results: dictionary in whic hto store results\n",
    "    \n",
    "    Outputs:\n",
    "    - dictionary storing results. Results include sparse pca object, transformed train and validation data '''\n",
    "    \n",
    "    print(\"Train shape\", train_df_pooled.shape)\n",
    "    \n",
    "    n_samples = train_df_pooled.shape[0]\n",
    "    total_var = np.trace( train_df_pooled.cov() )\n",
    "    \n",
    "    sparse_pca_results[alpha] = dict()\n",
    "    \n",
    "    # fit sparse pca\n",
    "    transformer = SparsePCA(n_components = n_components, random_state=3455, n_jobs = -1, alpha = alpha)\n",
    "    transformer.fit(train_df_pooled)\n",
    "\n",
    "    # project dataset onto a subspace (i.e. reduce dimensionality)\n",
    "    x_train_pca = transformer.transform(train_df_pooled)\n",
    "    x_val_pca = transformer.transform(val_df_pooled)\n",
    "    \n",
    "    \n",
    "    # Calculate explaend vairance ratio using QR decomposition (this is not used later on)\n",
    "    # Since principal components are not orthogonal explained variance is based on successive OLS models rather\n",
    "    # than covariance matrix eigenvalues.\n",
    "    q, r = np.linalg.qr(x_train_pca / np.sqrt(n_samples - 1) ) \n",
    "    \n",
    "    sparse_pca_results[alpha][\"explained_var\"] = np.diag(r**2) / total_var\n",
    "    sparsity = (np.abs( transformer.components_ ).sum(axis = 0) > 1e-5).sum(axis = 0)\n",
    "    \n",
    "    sparse_pca_results[alpha][\"total_var\"] = total_var\n",
    "    sparse_pca_results[alpha][\"sparsity\"] = sparsity\n",
    "\n",
    "    # project back to the original space\n",
    "    x_train_original_space = x_train_pca @ transformer.components_ # project back \n",
    "    x_val_original_space = x_val_pca @ transformer.components_ # project back\n",
    "    # calculate RMSE\n",
    "    loss = ((val_df_pooled - x_val_original_space) ** 2).sum().sum()/n_samples\n",
    "    \n",
    "    # store the results in a dictionary which is then returned\n",
    "    sparse_pca_results[alpha][\"spca_object\"] = transformer\n",
    "    sparse_pca_results[alpha][\"x_train\"] = x_train_pca \n",
    "    sparse_pca_results[alpha][\"x_val\"] = x_val_pca\n",
    "    sparse_pca_results[alpha][\"components\"] = transformer.components_\n",
    "\n",
    "    sparse_pca_results[alpha][\"x_train_original_space\"] = x_train_original_space\n",
    "    sparse_pca_results[alpha][\"x_val_original_space\"] = x_val_original_space\n",
    "    \n",
    "    sparse_pca_results[alpha][\"loss\"] = loss\n",
    "    print(loss)\n",
    "\n",
    "    dump_object(\"obj_\" + str(alpha) + \"_\" + str(n_components), sparse_pca_results)\n",
    "\n",
    "\n",
    "    return( sparse_pca_results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (1346, 36667)\n",
      "27822.23872040349\n",
      "--- 12106.216319799423 seconds ---\n"
     ]
    }
   ],
   "source": [
    "spca_results = dict()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "spca_results = dict()\n",
    "\n",
    "spca_results = calculate_sparse_pca(5, 250, train_df_pooled, val_df_pooled, spca_results)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (1346, 36667)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "spca_results = dict()\n",
    "\n",
    "spca_results = calculate_sparse_pca(2.5, 250, train_df_pooled, val_df_pooled, spca_results)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "spca_results = dict()\n",
    "\n",
    "spca_results = calculate_sparse_pca(0.1, 150, train_df_pooled, val_df_pooled, spca_results)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsof_env",
   "language": "python",
   "name": "gsof_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
